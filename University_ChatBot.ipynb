{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# load data from JSON file\n",
        "with open('intents.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# extract text and intent from data\n",
        "texts = []\n",
        "intents = []\n",
        "for intent in data['intents']:\n",
        "    for text in intent['text']:\n",
        "        texts.append(text)\n",
        "        intents.append(intent['intent'])\n",
        "\n",
        "# tokenize text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "encoded_texts = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# save tokenizer\n",
        "import pickle\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# pad sequences to have equal length\n",
        "max_len = max([len(x) for x in encoded_texts])\n",
        "padded_texts = pad_sequences(encoded_texts, maxlen=max_len, padding='post')\n",
        "\n",
        "# create label encoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# fit and transform the intents to integer labels\n",
        "encoded_intents = le.fit_transform(intents)\n",
        "\n",
        "# get the number of unique labels\n",
        "num_intents = len(le.classes_)\n",
        "\n",
        "# apply one-hot encoding to the integer labels\n",
        "encoded_intents = tf.one_hot(encoded_intents, depth=num_intents)\n",
        "\n",
        "# define model architecture\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len)(input_layer)\n",
        "lstm_layer = LSTM(128)(embedding_layer)\n",
        "output_layer = Dense(num_intents, activation='softmax')(lstm_layer)\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# train model\n",
        "model.fit(padded_texts, encoded_intents, epochs=50, batch_size=16)\n",
        "\n",
        "# save model\n",
        "model.save('chatbot_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcmhuZD8D4DV",
        "outputId": "d9e34842-843b-4847-ffcb-b5ca8ca526ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "26/26 [==============================] - 4s 17ms/step - loss: 3.6102 - accuracy: 0.0642\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 3.4861 - accuracy: 0.0691\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 3.2263 - accuracy: 0.1111\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 2.8975 - accuracy: 0.1802\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 2.6473 - accuracy: 0.2074\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 2.2949 - accuracy: 0.3086\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 1.9325 - accuracy: 0.4198\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 1.6031 - accuracy: 0.5407\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 1.2678 - accuracy: 0.6543\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.9755 - accuracy: 0.7358\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.8075 - accuracy: 0.7827\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.6394 - accuracy: 0.8346\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.4846 - accuracy: 0.8716\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.3623 - accuracy: 0.9111\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.2663 - accuracy: 0.9506\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.2121 - accuracy: 0.9630\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.1723 - accuracy: 0.9679\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.1326 - accuracy: 0.9778\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.1083 - accuracy: 0.9827\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0899 - accuracy: 0.9802\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0817 - accuracy: 0.9827\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 0s 15ms/step - loss: 0.0597 - accuracy: 0.9901\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0541 - accuracy: 0.9827\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0466 - accuracy: 0.9877\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0419 - accuracy: 0.9926\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.0389 - accuracy: 0.9877\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.0357 - accuracy: 0.9877\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 1s 21ms/step - loss: 0.0352 - accuracy: 0.9901\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.0337 - accuracy: 0.9901\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 1s 22ms/step - loss: 0.0297 - accuracy: 0.9901\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0280 - accuracy: 0.9926\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0272 - accuracy: 0.9926\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0277 - accuracy: 0.9901\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0253 - accuracy: 0.9901\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0247 - accuracy: 0.9926\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0242 - accuracy: 0.9926\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0236 - accuracy: 0.9926\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9852\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 0.9951\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9951\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.9926\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0197 - accuracy: 0.9926\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.9926\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9926\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0186 - accuracy: 0.9951\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9951\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9951\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9926\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9926\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 0.0448 - accuracy: 0.9802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# load data from JSON file\n",
        "with open('intents_final.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# extract text and intent from data\n",
        "texts = []\n",
        "intents = []\n",
        "for intent in data['intents']:\n",
        "    for text in intent['text']:\n",
        "        texts.append(text)\n",
        "        intents.append(intent['intent'])\n",
        "\n",
        "# tokenize text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "# load saved model\n",
        "model = load_model('chatbot_final.h5')\n",
        "\n",
        "# define maximum sequence length\n",
        "max_len = model.input_shape[1]\n",
        "\n",
        "# create label encoder object\n",
        "le = LabelEncoder()\n",
        "le.fit(intents)\n",
        "\n",
        "# create inverse mapping of label encoder for intent prediction\n",
        "intent_mapping = {i: label for i, label in enumerate(le.classes_)}\n",
        "\n",
        "# start chatbot interaction\n",
        "print('Welcome to the chatbot! Type \"quit\" to exit.')\n",
        "while True:\n",
        "    # get user input\n",
        "    user_input = input('You: ').lower().strip()\n",
        "    \n",
        "    # check if user wants to quit\n",
        "    if user_input == 'quit':\n",
        "        break\n",
        "    \n",
        "    # encode user input text\n",
        "    encoded_input = tokenizer.texts_to_sequences([user_input])\n",
        "    padded_input = pad_sequences(encoded_input, maxlen=max_len, padding='post')\n",
        "    \n",
        "    # predict intent\n",
        "    intent_prob = model.predict(padded_input)[0]\n",
        "    intent_idx = np.argmax(intent_prob)\n",
        "    intent_label = le.inverse_transform([intent_idx])[0]\n",
        "    \n",
        "    # retrieve response\n",
        "    for intent in data['intents']:\n",
        "        if intent['intent'] == intent_label:\n",
        "            response = np.random.choice(intent['responses'])\n",
        "            print('Chatbot:', response)\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "1oTJjRSxEkKs",
        "outputId": "b1a34800-e9f4-449b-89a6-a086f9c6efc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the chatbot! Type \"quit\" to exit.\n",
            "You: Hello\n",
            "1/1 [==============================] - 1s 547ms/step\n",
            "Chatbot: Good to see you again!\n",
            "You: Where is HOD?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot: All engineering departments have only one hod XYZ who available on (Place name)\n",
            "You: Where is cafateria?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot: Good to see you again!\n",
            "You: Where is Cafetaria?\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Chatbot: Our university has canteen with variety of food available\n",
            "You: how many departments are there in JUIT\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Chatbot: <a target=\"_blank\" href=\"ADD YOU GOOGLE MAP LINK HERE\"> here</a>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0448fee5e7f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# get user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# check if user wants to quit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4FxTiVkGAltd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}