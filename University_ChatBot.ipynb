{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8nRHYCe8bDi",
        "outputId": "09a2cbbe-88a0-4c71-b6ca-a32541b6bbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# load data from JSON file\n",
        "data=pd.read_csv(\"/content/20200325_counsel_chat.csv\")\n",
        "\n",
        "# extract text and intent from data\n",
        "texts = []\n",
        "intents = []\n",
        "for intent in data['questionID']:\n",
        "    for text in intent['questionText']:\n",
        "        texts.append(text)\n",
        "        intents.append(intent['intent'])\n",
        "\n",
        "# tokenize text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "encoded_texts = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# save tokenizer\n",
        "import pickle\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# pad sequences to have equal length\n",
        "max_len = max([len(x) for x in encoded_texts])\n",
        "padded_texts = pad_sequences(encoded_texts, maxlen=max_len, padding='post')\n",
        "\n",
        "# create label encoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# fit and transform the intents to integer labels\n",
        "encoded_intents = le.fit_transform(intents)\n",
        "\n",
        "# get the number of unique labels\n",
        "num_intents = len(le.classes_)\n",
        "\n",
        "# apply one-hot encoding to the integer labels\n",
        "encoded_intents = tf.one_hot(encoded_intents, depth=num_intents)\n",
        "\n",
        "# define model architecture\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len)(input_layer)\n",
        "lstm_layer = LSTM(128)(embedding_layer)\n",
        "output_layer = Dense(num_intents, activation='softmax')(lstm_layer)\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# train model\n",
        "model.fit(padded_texts, encoded_intents, epochs=50, batch_size=16)\n",
        "\n",
        "# save model\n",
        "model.save('chatbot_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "IcmhuZD8D4DV",
        "outputId": "aae37ea4-2f84-495f-e2ef-e9bb73399836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-afe11c9fb81a>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mintents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mintent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questionID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questionText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mintents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'intent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# load data from JSON file\n",
        "with open('intents_final.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# extract text and intent from data\n",
        "texts = []\n",
        "intents = []\n",
        "for intent in data['intents']:\n",
        "    for text in intent['text']:\n",
        "        texts.append(text)\n",
        "        intents.append(intent['intent'])\n",
        "\n",
        "# tokenize text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "# load saved model\n",
        "model = load_model('chatbot_final.h5')\n",
        "\n",
        "# define maximum sequence length\n",
        "max_len = model.input_shape[1]\n",
        "\n",
        "# create label encoder object\n",
        "le = LabelEncoder()\n",
        "le.fit(intents)\n",
        "\n",
        "# create inverse mapping of label encoder for intent prediction\n",
        "intent_mapping = {i: label for i, label in enumerate(le.classes_)}\n",
        "\n",
        "# start chatbot interaction\n",
        "print('Welcome to the chatbot! Type \"quit\" to exit.')\n",
        "while True:\n",
        "    # get user input\n",
        "    user_input = input('You: ').lower().strip()\n",
        "    \n",
        "    # check if user wants to quit\n",
        "    if user_input == 'quit':\n",
        "        break\n",
        "    \n",
        "    # encode user input text\n",
        "    encoded_input = tokenizer.texts_to_sequences([user_input])\n",
        "    padded_input = pad_sequences(encoded_input, maxlen=max_len, padding='post')\n",
        "    \n",
        "    # predict intent\n",
        "    intent_prob = model.predict(padded_input)[0]\n",
        "    intent_idx = np.argmax(intent_prob)\n",
        "    intent_label = le.inverse_transform([intent_idx])[0]\n",
        "    \n",
        "    # retrieve response\n",
        "    for intent in data['intents']:\n",
        "        if intent['intent'] == intent_label:\n",
        "            response = np.random.choice(intent['responses'])\n",
        "            print('Chatbot:', response)\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "1oTJjRSxEkKs",
        "outputId": "b1a34800-e9f4-449b-89a6-a086f9c6efc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the chatbot! Type \"quit\" to exit.\n",
            "You: Hello\n",
            "1/1 [==============================] - 1s 547ms/step\n",
            "Chatbot: Good to see you again!\n",
            "You: Where is HOD?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot: All engineering departments have only one hod XYZ who available on (Place name)\n",
            "You: Where is cafateria?\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Chatbot: Good to see you again!\n",
            "You: Where is Cafetaria?\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Chatbot: Our university has canteen with variety of food available\n",
            "You: how many departments are there in JUIT\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Chatbot: <a target=\"_blank\" href=\"ADD YOU GOOGLE MAP LINK HERE\"> here</a>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0448fee5e7f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# get user input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# check if user wants to quit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from fuzzywuzzy import process\n",
        "import random\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/orchid - 20200325_counsel_chat.csv.csv')\n",
        "\n",
        "# Convert the questionTitle to numerical labels using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "le.fit(data['questionTitle'])\n",
        "data['label'] = le.transform(data['questionTitle'])\n",
        "\n",
        "# Tokenize the input data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['questionText'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Pad the input sequences\n",
        "maxlen = max([len(x.split()) for x in data['questionText']])\n",
        "x = tokenizer.texts_to_sequences(data['questionText'])\n",
        "x = pad_sequences(x, padding='post', maxlen=maxlen)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 32))\n",
        "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the neural network\n",
        "model.fit(x, data['label'], epochs=50)\n",
        "\n",
        "# Define a function to generate responses from the neural network\n",
        "def generate_response(input_text):\n",
        "    # Find the question in the dataframe that is closest to the input text\n",
        "    closest_question = process.extractOne(input_text, data['questionText'])[0]\n",
        "    # Get the corresponding label for the closest question\n",
        "    label = data.loc[data['questionText'] == closest_question]['label'].values[0]\n",
        "    # Get a random answer belonging to the corresponding questionTitle\n",
        "    possible_answers = data.loc[data['label'] == label]['answerText'].values\n",
        "    response = random.choice(possible_answers)\n",
        "    return response\n",
        "\n",
        "# Start the chatbot\n",
        "print(\"Welcome to the chatbot!\")\n",
        "print(\"Type 'exit' to end the chatbot.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input == 'exit':\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "    else:\n",
        "        response = generate_response(user_input)\n",
        "        print(\"Chatbot: \", response)\n"
      ],
      "metadata": {
        "id": "4FxTiVkGAltd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ba7fd1-2901-431b-9385-1adbe20f4555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "67/67 [==============================] - 58s 791ms/step - loss: -1254.9589 - accuracy: 0.0019\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 46s 693ms/step - loss: -3506.1013 - accuracy: 0.0019\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 47s 697ms/step - loss: -4635.7725 - accuracy: 0.0019\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 47s 695ms/step - loss: -5581.3706 - accuracy: 0.0019\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 53s 790ms/step - loss: -6470.9893 - accuracy: 0.0019\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 46s 681ms/step - loss: -7331.6919 - accuracy: 0.0019\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 47s 708ms/step - loss: -8175.8477 - accuracy: 0.0019\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 46s 682ms/step - loss: -9008.9629 - accuracy: 0.0019\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 46s 694ms/step - loss: -9831.8994 - accuracy: 0.0019\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 45s 679ms/step - loss: -10651.1768 - accuracy: 0.0019\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 46s 684ms/step - loss: -11465.6729 - accuracy: 0.0019\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 47s 696ms/step - loss: -12276.9141 - accuracy: 0.0019\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 46s 679ms/step - loss: -13086.8379 - accuracy: 0.0019\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 46s 693ms/step - loss: -13893.2715 - accuracy: 0.0019\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 45s 677ms/step - loss: -14696.8027 - accuracy: 0.0019\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 47s 696ms/step - loss: -15498.1680 - accuracy: 0.0019\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 45s 677ms/step - loss: -16299.3721 - accuracy: 0.0019\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 46s 695ms/step - loss: -17097.7188 - accuracy: 0.0019\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 46s 681ms/step - loss: -17895.6309 - accuracy: 0.0019\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 46s 688ms/step - loss: -18692.8711 - accuracy: 0.0019\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 46s 689ms/step - loss: -19488.0820 - accuracy: 0.0019\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 45s 675ms/step - loss: -20285.0547 - accuracy: 0.0019\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 46s 690ms/step - loss: -21080.0430 - accuracy: 0.0019\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 45s 678ms/step - loss: -21874.2676 - accuracy: 0.0019\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 46s 693ms/step - loss: -22667.1816 - accuracy: 0.0019\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 45s 675ms/step - loss: -23458.6836 - accuracy: 0.0019\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 46s 692ms/step - loss: -24251.3379 - accuracy: 0.0019\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 45s 674ms/step - loss: -25043.3594 - accuracy: 0.0019\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 46s 694ms/step - loss: -25835.1113 - accuracy: 0.0019\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 45s 675ms/step - loss: -26625.7891 - accuracy: 0.0019\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 46s 685ms/step - loss: -27416.9473 - accuracy: 0.0019\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 45s 676ms/step - loss: -28207.6426 - accuracy: 0.0019\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 46s 686ms/step - loss: -28999.4238 - accuracy: 0.0019\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 46s 694ms/step - loss: -29788.6523 - accuracy: 0.0019\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 45s 679ms/step - loss: -30580.1211 - accuracy: 0.0019\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 46s 693ms/step - loss: -31369.9199 - accuracy: 0.0019\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 45s 676ms/step - loss: -32160.9316 - accuracy: 0.0019\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 47s 697ms/step - loss: -32950.2539 - accuracy: 0.0019\n",
            "Epoch 39/50\n",
            "67/67 [==============================] - 45s 678ms/step - loss: -33740.3203 - accuracy: 0.0019\n",
            "Epoch 40/50\n",
            "67/67 [==============================] - 46s 693ms/step - loss: -34529.1328 - accuracy: 0.0019\n",
            "Epoch 41/50\n",
            "67/67 [==============================] - 45s 671ms/step - loss: -35317.7695 - accuracy: 0.0019\n",
            "Epoch 42/50\n",
            "67/67 [==============================] - 46s 684ms/step - loss: -36108.4492 - accuracy: 0.0019\n",
            "Epoch 43/50\n",
            "67/67 [==============================] - 45s 676ms/step - loss: -36913.4805 - accuracy: 0.0019\n",
            "Epoch 44/50\n",
            "67/67 [==============================] - 46s 679ms/step - loss: -37833.6758 - accuracy: 0.0019\n",
            "Epoch 45/50\n",
            "67/67 [==============================] - 45s 674ms/step - loss: -38711.9336 - accuracy: 0.0019\n",
            "Epoch 46/50\n",
            "67/67 [==============================] - 46s 679ms/step - loss: -39567.5273 - accuracy: 0.0019\n",
            "Epoch 47/50\n",
            "67/67 [==============================] - 46s 681ms/step - loss: -40413.1445 - accuracy: 0.0019\n",
            "Epoch 48/50\n",
            "67/67 [==============================] - 45s 670ms/step - loss: -41251.7812 - accuracy: 0.0019\n",
            "Epoch 49/50\n",
            "67/67 [==============================] - 46s 683ms/step - loss: -42085.2070 - accuracy: 0.0019\n",
            "Epoch 50/50\n",
            "67/67 [==============================] - 45s 673ms/step - loss: -42916.4023 - accuracy: 0.0019\n",
            "Welcome to the chatbot!\n",
            "Type 'exit' to end the chatbot.\n",
            "You: I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n",
            "Chatbot:  I am sorry you are feeling this way.  We all have narratives that we say to ourselves whether it is valid or not.  In your case it would be beneficial to explore when and how this belief began and rewrite your story.  There are different ways to explore and rewrite.  This process requires commitment, self-reflection and courage.\n",
            "You: I am not sure if I am depressed. I don't know how to bring it up to my parents, and that makes me miserable.\n",
            "Chatbot:  I am so sorry you are struggling!  I do think it's a good idea to share your feelings with your parents and perhaps get some help connecting with a counselor or therapist if you feel that might help.  There are lots of ways to tell them, depending on your relationship.  Maybe saying \"I wanted to tell you guys something.. sometimes I worry that I might be depressed.\" Or, some folks will write a letter, or even send a text.  The most important thing is that you tell someone you trust so you don't feel so miserable. I hope this helps.  Best of luck.\n",
            "You: Why am I so afraid of it? I don't understand.\n",
            "Chatbot:  Why are you afraid of rape? Because it is a problem in the United States! The National Sexual Violence Resource Center reports that one in five women (0r 20%) will be raped (http://www.nsvrc.org/sites/default/files/publications_nsvrc_factsheet_media-packet_statistics-about-sexual-violence_0.pdf) and that 80% of women know their assailant. Given these statistics, it is perfectly logical to be afraid. However, there are things you can do to reduce the risk of rape, such as being aware of your surroundings, and limiting the use of drugs or alcohol.The Enhanced Access, Knowledge, Act program for college-aged women has been shown to reduce the risk of rape by more than 50%. (http://www.blueprintsprograms.com/factsheet/eaaa-enhanced-assess-acknowledge-act-sexual-assault-resistance-education) You may want to see if a program like this is available in your area. Another great app for when you need to walk somewhere alone, is the Companion App (http://www.companionapp.io). Friends or family can track your progress from one point to another via the GPS in your phone.In addition, talking with a counselor about your fears would also be a good idea. Sometimes fears are rational and reasonable. Sometimes they are over-reactions and unreasonable. When then are over-reactions and unreasonable, they can have a negative impact on your life. In this case, a counselor could help you understand why your fears are unreasonable, and how you can stop them from negatively impacting your life.\n",
            "You: am i depressed?\n",
            "Chatbot:  It's important to take a look inside and see what's going on with you to cause you to have these feelings.  Please contact us in whatever way is most comfortable for you and we can get you set up with someone who will help you figure out this space in your life.\n",
            "You: hi\n",
            "Chatbot:  Answers about our inner lives are most successfully reached from a sense of feeling grounded in oneself.First step is to accept your nervousness and restless sleep.  As often as possible, sleep during daytimes in order for your body to catch up on its need for rest.Accept too about feeling down.  It is normal to feel down once in a while.  From this place of self-acceptance, trust any answers which come up to your mind.  Often answers about complicated topics come in small pieces, not all at once as a whole unit.Also, your description about panic attacks is also completely normal.   They often arise unrelated to particular conditions at a given moment.  They are a healthy symptom your body is trying to expel bad feelings and does this by having the anxiety erupt at times.So, self-acceptance, tolerance of being on a process of clearing out worn out emotional clutter, and sleep at odd times if possible, are all ways to stabilize yourself, which will also feel calm and good!\n",
            "You: quit\n",
            "Chatbot:  After stopping the abuse of alcohol, depressive symptoms are common. She may benefit from exploring why she wants to move and see if she would still want to move if she did not feel depressed. 12 step meetings can also be helpful.\n",
            "You: exit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqvswMRrUJV3",
        "outputId": "f92936b1-13d3-410d-c823-0409c4542f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDimgJ82UMF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}